{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1247d0b-d723-48cf-a5c8-0a4e6ef1e69f",
   "metadata": {},
   "source": [
    "# iEEG Pipeline Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d7a5bd-41ac-4d3b-a38c-c8ccfc86f7ee",
   "metadata": {},
   "source": [
    "This notebook is meant to demonstrate how the core libraries for iEEG processing can be combined to make a user-friendly pipeline.\n",
    "\n",
    "The code presented in this example is in no way exhaustive. Personal code can be integrated into this pipeline, and these functions are simple meant to help outline a project and ensure that researchers use the same libraries when possible.\n",
    "\n",
    "This code is not meant to be used in a CI/CD style pipeline. We have opted for a lightweight solution for the purposes of individual research. If you require a larger scaleable solution to code deployment, please reach out to the [Brian Prager](mailto:bjprager@seas.upenn.edu) or [Joshua Asuncion](asuncion@seas.upenn.edu) for help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab175e94-7589-4d7b-8606-c1d34e15129f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398bf3fb-e0c2-433d-8bf5-a1d78705ecea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import sys\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b97d50-07c9-4cd2-9c13-30c461439545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pipeline imports\n",
    "from pipeline_ieeg.data_pull import pipeline_datapull_ieeg as PDI\n",
    "from pipeline_ieeg.data_quality import dataframe_properties_check as DPC\n",
    "from pipeline_ieeg.preprocessing import pipeline_preprocessing_ieeg as PPI\n",
    "from pipeline_ieeg.feature_selection import pipeline_feature_selection_ieeg as PFSI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbb82cd-a23f-465e-8947-a6d0f5c42e7d",
   "metadata": {},
   "source": [
    "The pipeline functions shown above have all been designed to reference the core libraries. This ensures that everyone is using the same core libraries when possible. It also allows for quick hot swapping of various analysis techniques. When appropriate, each function can take in a list of processing step, or each step can be called individually. We will provide a demonstration below for what this means for analysis.\n",
    "\n",
    "Generally, pipeline functions will follow the structure shown in the import statement. In the case of iEEG, that means the module is named pipeline_ieeg.\n",
    "\n",
    "The directory underneath is broken up by processing step:\n",
    "1. data pull\n",
    "2. data quality check\n",
    "3. preprocessing\n",
    "4. feature selection\n",
    "5. model\n",
    "6. data reporting\n",
    "\n",
    "Finally, the format for the script will typically take the form of pipeline_**processing step**_ieeg. (Data quality is linked to unit testing, and as of 02/21/2023 does not follow this format.)\n",
    "\n",
    "**For more information on each of the pipeline functions or core libraries, please reference the relevant examples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11a67c9a-83dc-4ba1-b296-99f946a76bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Calls series of commands for a simple ieeg pipeline.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Cleaned dataframe, sampling frequency, and a dictionary of features.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Command line options needed to obtain data.\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-u', '--user', required=True, help='username')\n",
    "    parser.add_argument('-p', '--password', help='password (will be prompted if omitted)')\n",
    "    parser.add_argument('--dataset', help='dataset name')\n",
    "    parser.add_argument('--start', type=int, help='start offset in usec')\n",
    "    parser.add_argument('--duration', type=int, help='number of usec to request')\n",
    "    parser.add_argument('--local_path', default=None, type=str, help='Path to local data to ingest manually. Default=None.')\n",
    "    parser.add_argument('--silent', dest='verbose', default=True, action='store_false', help='Silent Verbose Output. Default=False.')\n",
    "    parser.add_argument('--nchan', type=int, help='Number of channels')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Data ingestion\n",
    "    DF,fs = PDI.main(args)\n",
    "    \n",
    "    # Data quality check\n",
    "    qflag = DPC.main(DF,16,verbose=args.verbose)\n",
    "    if qflag and args.verbose:\n",
    "        print(\"All data quality checks came back True. Proceeding to next step.\")\n",
    "    \n",
    "    # Data preprocessing\n",
    "    DF = PPI.main(DF)\n",
    "    \n",
    "    # Feature selection\n",
    "    feature_dict = PFSI.main(DF,fs)\n",
    "    \n",
    "    return DF,fs,feature_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9c4a71-e83a-443f-93f8-84ff25d9f1c8",
   "metadata": {},
   "source": [
    "This function (named main to provide a simple consistent naming convention when building modules) goes through an entire iEEG processing pipeline. For specific examples of how each function works, please see below.\n",
    "\n",
    "### Command-line Arguments\n",
    "At a high level, the code begins by requesting information from the user. Most of this information is to help identify the dataset the user wishes to analyze. Additional pipeline options can be added if specific information needs to be passed to the data reduction or modeling code.\n",
    "\n",
    "### Data Ingestion\n",
    "At the data ingestion step, the code performs a series of checks to prevent data duplication. It will first check for data that matches the provided criteria in the user_data folder of the repository. Alternatively, it will check the file location provided by args.local_path. If the file is not found, it will then check against Borel and Lief. If the data does not exist within our cache, only then will it try to connect through the iEEG API to download the new data.\n",
    "\n",
    "### Data Quality\n",
    "This code checks the dataframe or array properties against expectation. This includes array shape, data types, and the presence of data like infs or NaNs. This type of code also aligns closely with unit testing, and may be cross referenced to the unit_test folder at the top of the repository. Not all unit tests are quality checks, so ask yourself what sort of \"issues\" your data may have you wish to be alerted to before running the pipeline.\n",
    "\n",
    "### Preprocessing\n",
    "This part of the code performs preprocessing on the data. Specific examples of how to use this function are provided below.\n",
    "\n",
    "### Feature selection\n",
    "This part of the code performs feature selection on the data. Specific examples of how to use this function are provided below. It returns a new object that contains the results of each feature selection within a dictionary where the key is the name of the feature, and the value is the result.\n",
    "\n",
    "### Output\n",
    "We then provide the output back to the user. If we were running a specific model, we could instead call it here. Or pass the data to a third party piece of software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e997579-12fa-4cb7-bd02-8fd3b3a3fb73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
